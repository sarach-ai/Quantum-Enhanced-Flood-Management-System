{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iPCc9RBAhwdc"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "class DatasetHandler:\n",
    "    def __init__(self, dataset_path):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.train_dir = os.path.join(dataset_path, \"train\")\n",
    "        self.test_dir = os.path.join(dataset_path, \"test\")\n",
    "        self.train_csv = os.path.join(dataset_path, \"train.csv\")\n",
    "        self.test_csv = os.path.join(dataset_path, \"test.csv\")\n",
    "\n",
    "    def load_paths_labels_from_csv(self, split=\"train\", img_ext=\".png\"):\n",
    "        \"\"\"\n",
    "        split: 'train' or 'test'\n",
    "        \"\"\"\n",
    "        if split == \"train\":\n",
    "            img_dir = self.train_dir\n",
    "            csv_path = self.train_csv\n",
    "        elif split == \"test\":\n",
    "            img_dir = self.test_dir\n",
    "            csv_path = self.test_csv\n",
    "        else:\n",
    "            raise ValueError(\"split must be 'train' or 'test'\")\n",
    "\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        imgs_path = []\n",
    "        imgs_label = []\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            img_id = str(row.iloc[0])\n",
    "            no_flood = row.iloc[1]\n",
    "            flood = row.iloc[2]\n",
    "\n",
    "            # Binary class encoding\n",
    "            # 0 -> no flood, 1 -> flood\n",
    "            label = 0 if no_flood == 1 else 1\n",
    "\n",
    "            img_path = os.path.join(img_dir, img_id)\n",
    "\n",
    "            if os.path.exists(img_path):\n",
    "                imgs_path.append(img_path)\n",
    "                imgs_label.append(label)\n",
    "            else:\n",
    "                print(f\"Warning: image not found -> {img_path}\")\n",
    "\n",
    "        # Shuffle paths and labels together\n",
    "        c = list(zip(imgs_path, imgs_label))\n",
    "        random.shuffle(c)\n",
    "        imgs_path, imgs_label = zip(*c)\n",
    "\n",
    "        return np.array(imgs_path), np.array(imgs_label)\n",
    "\n",
    "    def train_validation_split(self, images, labels, split_factor=0.2):\n",
    "        val_size = int(len(images) * split_factor)\n",
    "        train_size = len(images) - val_size\n",
    "\n",
    "        return (\n",
    "            images[:train_size],\n",
    "            labels[:train_size],\n",
    "            images[train_size:],\n",
    "            labels[train_size:]\n",
    "        )\n",
    "\n",
    "    def cnn_data_loader(self, imgs_path, imgs_label,\n",
    "                        batch_size=16,\n",
    "                        img_shape=(64, 64, 3),\n",
    "                        n_classes=2):\n",
    "\n",
    "        batch_in = np.zeros((batch_size, *img_shape))\n",
    "        batch_out = np.zeros((batch_size, n_classes))\n",
    "\n",
    "        while True:\n",
    "            for i in range(batch_size):\n",
    "                index = random.randint(0, len(imgs_path) - 1)\n",
    "\n",
    "#               batch_in[i] = plt.imread(imgs_path[index]) / 255.0\n",
    "\n",
    "                # img = Image.open(imgs_path[index]).convert(\"RGB\")\n",
    "                # img = img.resize((img_shape[1], img_shape[0]))  # (64, 64)\n",
    "                # img = np.array(img) / 255.0                     # (64, 64, 3)\n",
    "                # batch_in[i] = np.transpose(img, (2, 0, 1))      # (3, 64, 64)\n",
    "\n",
    "                # assert img.shape == (img_shape[0], img_shape[1], img_shape[2])\n",
    "\n",
    "                img = plt.imread(imgs_path[index])\n",
    "\n",
    "                # resize explicitly\n",
    "                img = np.array(\n",
    "                    Image.fromarray((img * 255).astype(np.uint8)).resize(\n",
    "                        (img_shape[1], img_shape[0])\n",
    "                    )\n",
    "                ) / 255.0\n",
    "\n",
    "                # channel-last → channel-first (explicit axes)\n",
    "              #  batch_in[i] = np.transpose(img, (2, 0, 1))\n",
    "\n",
    "                batch_in[i] = img\n",
    "\n",
    "\n",
    "                label = imgs_label[index]\n",
    "                one_hot = np.zeros(n_classes)\n",
    "                one_hot[label] = 1\n",
    "                batch_out[i] = one_hot\n",
    "\n",
    "            yield batch_in, batch_out\n",
    "\n",
    "    def qcnn_data_loader(self, imgs_path, imgs_label,\n",
    "                         batch_size=1,\n",
    "                         img_shape=(64, 64, 3),\n",
    "                         returnpath=False):\n",
    "\n",
    "        batch_in = np.zeros((batch_size, img_shape[2], img_shape[0], img_shape[1]))\n",
    "        batch_out = np.zeros(batch_size)\n",
    "\n",
    "        while True:\n",
    "            for i in range(batch_size):\n",
    "                index = random.randint(0, len(imgs_path) - 1)\n",
    "                # batch_in[i] = np.transpose(\n",
    "                #     plt.imread(imgs_path[index]) / 255.0\n",
    "                # )\n",
    "\n",
    "                img = plt.imread(imgs_path[index])\n",
    "\n",
    "                # ensure RGB\n",
    "                if img.ndim == 2:  # grayscale\n",
    "                    img = np.stack([img]*3, axis=-1)\n",
    "\n",
    "                # resize to expected spatial size\n",
    "                img = np.array(\n",
    "                    Image.fromarray((img * 255).astype(np.uint8))\n",
    "                        .resize((img_shape[1], img_shape[0]))\n",
    "                ) / 255.0\n",
    "\n",
    "                # explicit channel-first\n",
    "                batch_in[i] = np.transpose(img, (2, 0, 1))\n",
    "\n",
    "\n",
    "                batch_out[i] = imgs_label[index]\n",
    "\n",
    "            if returnpath:\n",
    "                yield (\n",
    "                    torch.Tensor(batch_in),\n",
    "                    torch.Tensor(batch_out).long(),\n",
    "                    imgs_path[index]\n",
    "                )\n",
    "            else:\n",
    "                yield (\n",
    "                    torch.Tensor(batch_in),\n",
    "                    torch.Tensor(batch_out).long()\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wBfl0HmbuLs7",
    "outputId": "fc0bacfc-d972-4a47-907d-10997c2e2479"
   },
   "outputs": [],
   "source": [
    "!pip install 'qiskit>=1.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V1smfxIavBQt",
    "outputId": "9cd72606-ed79-4235-e9e2-c5c1801768fc"
   },
   "outputs": [],
   "source": [
    "!pip install qiskit-aer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-C6jp7jrr9mv",
    "outputId": "33020739-8c9b-4072-8fa2-155e8a2921e0"
   },
   "outputs": [],
   "source": [
    "!pip install pylatexenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TTe0ZiaGsSkt",
    "outputId": "8bbd0773-f4fb-4370-b341-2fd341025eff"
   },
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C9XgMNeFrxxR"
   },
   "outputs": [],
   "source": [
    "from qiskit import QuantumRegister, ClassicalRegister, QuantumCircuit\n",
    "from qiskit_aer import AerSimulator, Aer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sYNrR6eosZyG"
   },
   "outputs": [],
   "source": [
    "from qiskit import QuantumRegister, ClassicalRegister, QuantumCircuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HrJke0esslWf"
   },
   "outputs": [],
   "source": [
    "from qiskit_aer import AerSimulator, Aer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1eaVt9NusnpC"
   },
   "outputs": [],
   "source": [
    "import qiskit\n",
    "from qiskit.circuit import Parameter,ControlledGate\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IUXL5JZvsn_Y",
    "outputId": "8d924eb8-736d-4aed-8bbb-565537f6474d"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda:0\")\n",
    "  print(\"Running on the GPU\")\n",
    "else:\n",
    "  device = torch.device(\"cpu\")\n",
    "  print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yJDJV1tKs2Ye"
   },
   "outputs": [],
   "source": [
    "#np.random.seed = 314\n",
    "\n",
    "NUM_QUBITS = 4\n",
    "NUM_SHOTS = 800 #3000\n",
    "SHIFT = np.pi/4\n",
    "LEARNING_RATE = 0.0002\n",
    "MOMENTUM = 0.5\n",
    "\n",
    "SIMULATOR = Aer.get_backend('qasm_simulator')\n",
    "#SIMULATOR = AerSimulator(method='automatic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xSg1bB9wuHwJ",
    "outputId": "c7db5bea-204f-4ae7-af4b-f66a61bca986"
   },
   "outputs": [],
   "source": [
    "# create list of all possible outputs of quantum circuit (2**NUM_QUBITS possible)\n",
    "import itertools\n",
    "def create_QC_OUTPUTS():\n",
    "    measurements = list(itertools.product([0, 1], repeat=NUM_QUBITS))\n",
    "    return [''.join([str(bit) for bit in measurement]) for measurement in measurements]\n",
    "\n",
    "QC_OUTPUTS = create_QC_OUTPUTS()\n",
    "print(QC_OUTPUTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fHunciJ_t8Rv"
   },
   "outputs": [],
   "source": [
    "class QiskitCircuit():\n",
    "\n",
    "\n",
    "    def __init__(self, n_qubits, backend, shots):\n",
    "        # --- Circuit definition ---\n",
    "        n_qubits = 4\n",
    "        self.circuit = qiskit.QuantumCircuit(n_qubits)\n",
    "        self.n_qubits = n_qubits\n",
    "        self.thetas = [Parameter(f\"theta_{i}\") for i in range(4)]\n",
    "        self.circuit.h(0)\n",
    "        self.circuit.cx(0, 1)\n",
    "        self.circuit.cx(1, 2)\n",
    "        self.circuit.cx(3, 2)\n",
    "\n",
    "        self.circuit.barrier()\n",
    "\n",
    "        for k in range(0, 4):\n",
    "            self.circuit.ry(self.thetas[k], k)\n",
    "\n",
    "        self.circuit.barrier()\n",
    "\n",
    "        self.circuit.cx(1, 0)\n",
    "        self.circuit.cx(2, 1)\n",
    "        self.circuit.cx(1, 0)\n",
    "\n",
    "        self.circuit.measure_all()\n",
    "        # ---------------------------\n",
    "\n",
    "        self.backend = backend\n",
    "        self.shots = shots\n",
    "\n",
    "\n",
    "    def N_qubit_expectation_Z(self,counts, shots, nr_qubits):\n",
    "        expects = np.zeros(len(QC_OUTPUTS))\n",
    "        for k in range(len(QC_OUTPUTS)):\n",
    "            key = QC_OUTPUTS[k]\n",
    "            perc = counts.get(key, 0)/shots\n",
    "            expects[k] = perc\n",
    "        return expects\n",
    "\n",
    "\n",
    "    def run(self, params_tensor):\n",
    "        # params_tensor: torch.Tensor of shape (NUM_QUBITS,)\n",
    "\n",
    "        # 1. Convert to Python floats\n",
    "        param_values = params_tensor.detach().cpu().numpy().tolist()\n",
    "\n",
    "        # 2. Build a TRUE Parameter → value dict\n",
    "        param_bind = {\n",
    "            param: val\n",
    "            for param, val in zip(self.circuit.parameters, param_values)\n",
    "        }\n",
    "\n",
    "        # 3. Bind parameters to circuit\n",
    "        bound_circuit = self.circuit.assign_parameters(param_bind)\n",
    "        \n",
    "        # 4. Run the bound circuit\n",
    "        job_sim = SIMULATOR.run(bound_circuit, shots=self.shots)\n",
    "\n",
    "        result_sim = job_sim.result()\n",
    "        counts = result_sim.get_counts(bound_circuit)\n",
    "\n",
    "        return self.N_qubit_expectation_Z(\n",
    "            counts, self.shots, self.n_qubits\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "id": "2a3DZpOUvaHr",
    "outputId": "d486b66c-35c5-4352-ff6d-4592081574f4"
   },
   "outputs": [],
   "source": [
    "circuit = QiskitCircuit(NUM_QUBITS, SIMULATOR, NUM_SHOTS)\n",
    "#print('Expected value for rotation [pi/4]: {}'.format(circuit.run(torch.Tensor([np.pi/4]*NUM_QUBITS))))\n",
    "circuit.circuit.draw(output='mpl')#, filename='Figures/{}-qubit circuit ryN.jpg'.format(NUM_QUBITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kDal5w3axCxw"
   },
   "outputs": [],
   "source": [
    "class TorchCircuit(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        if not hasattr(ctx, 'QiskitCirc'):\n",
    "            ctx.QiskitCirc = QiskitCircuit(NUM_QUBITS, SIMULATOR, shots=NUM_SHOTS)\n",
    "\n",
    "        exp_value = ctx.QiskitCirc.run(i)\n",
    "\n",
    "        result = torch.tensor([exp_value])\n",
    "\n",
    "        ctx.save_for_backward(result, i)\n",
    "\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "\n",
    "        forward_tensor, i = ctx.saved_tensors\n",
    "#         print('forward_tensor = {}'.format(forward_tensor))\n",
    "        input_numbers = i\n",
    "#         print('input_numbers = {}'.format(input_numbers))\n",
    "        gradients = torch.Tensor()\n",
    "\n",
    "        for k in range(1*NUM_QUBITS):\n",
    "            shift_right = input_numbers.detach().clone()\n",
    "            shift_right[k] = shift_right[k] + SHIFT\n",
    "            shift_left = input_numbers.detach().clone()\n",
    "            shift_left[k] = shift_left[k] - SHIFT\n",
    "\n",
    "#             print('shift_right = {}, shift_left = {}'.format(shift_right, shift_left))\n",
    "\n",
    "            expectation_right = ctx.QiskitCirc.run(shift_right)\n",
    "            expectation_left  = ctx.QiskitCirc.run(shift_left)\n",
    "#             print('expectation_right = {}, \\nexpectation_left = {}'.format(expectation_right, expectation_left))\n",
    "\n",
    "            gradient = torch.tensor([expectation_right]) - torch.tensor([expectation_left])\n",
    "            # rescale gradient\n",
    "#             gradient = gradient / torch.norm(gradient)\n",
    "#             print('gradient for k={}: {}'.format(k, gradient))\n",
    "            gradients = torch.cat((gradients, gradient.float()))\n",
    "\n",
    "        result = torch.Tensor(gradients)\n",
    "#         print('gradients = {}'.format(result))\n",
    "#         print('grad_output = {}'.format(grad_output))\n",
    "\n",
    "        return (result.float() * grad_output.float()).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9-eEo2mByANH"
   },
   "outputs": [],
   "source": [
    "dataset_root = '/Users/shaheer/NUST/QCHack/archive (2)'\n",
    "handler = DatasetHandler(dataset_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZuK5q2gqyKVT"
   },
   "outputs": [],
   "source": [
    "classes = ['flood','no flood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4jTeQ7I9yNdh",
    "outputId": "f508d4e9-0c81-441e-9d4d-5a2e52c5fc41"
   },
   "outputs": [],
   "source": [
    "handler = DatasetHandler(dataset_root)\n",
    "\n",
    "imgs_path, imgs_label = handler.load_paths_labels_from_csv(split=\"train\")\n",
    "print('Dataset images:', len(imgs_path))\n",
    "print('Dataset labels:', len(imgs_label))\n",
    "print('Dataset sample ->', imgs_path[0], imgs_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ICjHC9YxDBJK",
    "outputId": "088907d9-58fc-4771-cda0-15bd2c50994c"
   },
   "outputs": [],
   "source": [
    "train_imgs, train_labels, val_imgs, val_labels = handler.train_validation_split(\n",
    "    imgs_path, imgs_label, split_factor=0.2\n",
    ")\n",
    "\n",
    "print('X_train shape:', train_imgs.shape, 'Y_train shape:', train_labels.shape)\n",
    "print('  X_val shape:', val_imgs.shape, '  Y_val shape:', val_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VsILt8LEDHGW"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "\n",
    "        self.fc4 = nn.Linear(2304, 1*NUM_QUBITS)\n",
    "\n",
    "        self.qc = QiskitCircuit(NUM_QUBITS, SIMULATOR, shots=NUM_SHOTS)\n",
    "\n",
    "        self.fc5 = nn.Linear(16, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # CNN feature extraction\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv3(x), 2))\n",
    "\n",
    "        x = x.view(-1, 2304)\n",
    "        \n",
    "        # Reduce to quantum circuit parameters\n",
    "        x = self.fc4(x)\n",
    "        x = np.pi*torch.tanh(x)\n",
    "\n",
    "        # Run through quantum circuit\n",
    "        x_for_qc = x[0, :len(self.qc.circuit.parameters)]\n",
    "        x = self.qc.run(x_for_qc)\n",
    "        \n",
    "        # Convert to tensor and add batch dimension\n",
    "        x = torch.tensor([x], dtype=torch.float32)\n",
    "\n",
    "        # Final classification layer\n",
    "        x = self.fc5(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "    def predict(self, x):\n",
    "        # apply softmax\n",
    "        pred = self.forward(x)\n",
    "        ans = torch.argmax(pred[0]).item()\n",
    "        return torch.tensor(ans)\n",
    "\n",
    "network = Net()#.to(device)\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uaJ5uHhTDS48"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "#from torchsummary import summary\n",
    "#summary(network, (3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C6Ku_Jr4DWII"
   },
   "outputs": [],
   "source": [
    "train_loader = iter(handler.qcnn_data_loader(train_imgs, train_labels, batch_size = 1, img_shape = (64,64,3)))\n",
    "test_loader = iter(handler.qcnn_data_loader(val_imgs, val_labels, batch_size = 1, img_shape = (64,64,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Npm2fW0lDdBF"
   },
   "outputs": [],
   "source": [
    "# Uncomment to load a pre-trained model\n",
    "# checkpoint = torch.load('/Users/shaheer/NUST/QCHack/model-bell-2.pt')\n",
    "# network.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# epoch = checkpoint['epoch']\n",
    "# loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "UXaBfeqzDedk",
    "outputId": "a47782cd-02a4-4780-a23f-194316c5fe21"
   },
   "outputs": [],
   "source": [
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "epochs = 50\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  train_loader = iter(handler.qcnn_data_loader(train_imgs, train_labels, batch_size = 1, img_shape = (64,64,3)))\n",
    "  test_loader = iter(handler.qcnn_data_loader(val_imgs, val_labels, batch_size = 1, img_shape = (64,64,3)))\n",
    "  total_loss = []\n",
    "\n",
    "\n",
    "  for batch_idx in range(len(train_labels)):\n",
    "    data, target = next(train_loader)\n",
    "    # print(batch_idx)\n",
    "    optimizer.zero_grad()\n",
    "    # Forward pass\n",
    "    output = network(data)\n",
    "    # Calculating loss\n",
    "    loss = loss_func(output, target)\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    # Optimize the weights\n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss.append(loss.item())\n",
    "\n",
    "    print('\\r Epoch %d ~ Batch %d (%d) ~ Loss %f ' % (epoch, batch_idx, len(train_imgs)-1, loss.item()), end='\\t\\t')\n",
    "\n",
    "  with torch.no_grad():\n",
    "    val_loss = []\n",
    "    targets = []\n",
    "    predictions = []\n",
    "    for batch_idx in range(len(val_imgs)):\n",
    "      data, target = next(test_loader)\n",
    "      output = network(data)\n",
    "      loss = loss_func(output, target)\n",
    "      val_loss.append(loss.item())\n",
    "\n",
    "      targets.append(target.item())\n",
    "\n",
    "      predictions.append(network.predict(data).item())\n",
    "\n",
    "\n",
    "  train_loss_list.append(sum(total_loss)/len(total_loss))\n",
    "  val_loss_list.append(sum(val_loss)/len(val_loss))\n",
    "\n",
    "  print('Training [{:.0f}%]\\t Training Loss: {:.4f} Validation Loss: {:.4f}'.format(\n",
    "      100. * (epoch + 1) / epochs, train_loss_list[-1], val_loss_list[-1]))\n",
    "\n",
    "  if epoch % 3 == 1:\n",
    "    print(confusion_matrix(targets, predictions,normalize='true'))\n",
    "    print(classification_report(targets, predictions, target_names=classes, digits=4))\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': network.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': train_loss_list[-1],\n",
    "            }, '/Users/shaheer/NUST/QCHack/model-bell-2.pt')\n",
    "    #torch.save(network.state_dict(), '/Users/shaheer/NUST/QCHack/model-bell.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iSD2sMOgDqZa"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_loss_list)\n",
    "plt.plot(val_loss_list)\n",
    "plt.title('Hybrid NN Training Convergence for {}-qubit'.format(NUM_QUBITS))\n",
    "plt.xlabel('Training Iterations')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.legend(['Training', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Rzf3ORMDq7V"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def func(x, a, b, c):\n",
    "  return a * np.exp(-b * x) + c\n",
    "\n",
    "x = np.linspace(0,len(train_loss_list),len(train_loss_list))\n",
    "y = func(x, 2.5, 1.3, 0.5)\n",
    "yn = np.array(val_loss_list)\n",
    "\n",
    "popt, pcov = curve_fit(func, x, yn)\n",
    "\n",
    "plt.figure()\n",
    "x1 = np.linspace(0,100+len(train_loss_list),100+len(train_loss_list))\n",
    "plt.plot(x, yn, 'ko', label=\"Loss\")\n",
    "plt.plot(x1, func(x1, *popt), 'r-', label=\"Fitted Curve\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ANlIEBH0Ds2E"
   },
   "outputs": [],
   "source": [
    "test_loader = iter(handler.qcnn_data_loader(val_imgs, val_labels, batch_size = 1, img_shape = (64,64,3)))\n",
    "accuracy = 0\n",
    "number = 0\n",
    "\n",
    "predictions = []\n",
    "targets = []\n",
    "\n",
    "for ct in range(len(val_imgs)):\n",
    "\n",
    "  data, target = next(test_loader)\n",
    "  number +=1\n",
    "  output = network.predict(data).item()\n",
    "\n",
    "  predictions.append(output)\n",
    "  targets.append(target.item())\n",
    "\n",
    "  accuracy += (output == target[0].item())*1\n",
    "  print('\\r ' + str(ct), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JnQy5UErDu4w"
   },
   "outputs": [],
   "source": [
    "plt.hist(targets, bins = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gElO5oV_DwjY"
   },
   "outputs": [],
   "source": [
    "print(\"Performance on test data is : {}/{} = {}%\".format(accuracy,number,100*accuracy/number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hoj4dWkoDycZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "cm = confusion_matrix(targets, predictions,normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Na7iL8oOD0U5"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 1, ncols = 1, figsize = (12,10))\n",
    "\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=classes)\n",
    "cmd.plot(ax=axes, cmap='Blues', xticks_rotation='vertical')\n",
    "print('S2')\n",
    "print('Accuracy:', cm.diagonal(), 'mean: ', cm.diagonal().mean())\n",
    "print(classification_report(targets, predictions, target_names=classes, digits=4))\n",
    "axes.get_images()[0].set_clim(0, 1)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
